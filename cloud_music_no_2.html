<!DOCTYPE html>
<html>

<head>
    <meta http-equiv='cache-control' content='no-cache'>
    <meta http-equiv='expires' content='0'>
    <meta http-equiv='pragma' content='no-cache'>
    <title>Cloud Music No. 2</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="dat.gui.js"></script>
    <script src="jquery.js"></script>
    <script src="p5.js"></script>
    <script src="sprintf.js"></script>
    <script src="three.js"></script>
    <script src="ace.js"></script>
    <script src="tinycolor.js"></script>
    <script src="CsoundAudioNode.js"></script>
    <script src="CsoundAC.js"></script>
    <link rel="stylesheet" href="w3.css">
    <link rel="icon" href="data:,">
    <style>
        .w3-container {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
        }

        .w3-bar {
            z-index: 1;
        }
    </style>
</head>

<body id="body" class="w3-medium w3-text-sand" style="height:100vh;">
    <script>
        if ('caches' in window) {
            caches.keys().then(function (names) {
                for (let name of names)
                    caches.delete(name);
                console.log(`deleted ${name} from caches.`);
            });
        }
    </script>
    <!------------------------------------------------------------------------
    This piece consists of an actual composition, which may include a Csound 
    orchestra, WebGL, a GLSL shader, JavaScript for generating scores (perhaps
    using the CsoundAC library), controls for the user to adjust the settings 
    of the piece or to control it in real time, license information, and 
    program notes. These are the parts that need to be written to create a new
    piece.
     
    There is also much "infrastructure" code that sets up the user interface, 
    compiles the Csound orchestra, compiles any GLSL shaders, and handles 
    all events from the user interface. Most of this code requires little or 
    no change when writing a new piece.
    ------------------------------------------------------------------------->
    <div class="w3-bar " style="position:fixed;background:transparent;">
        <ul class="menu">
            <li id="menu_item_play" class="w3-btn w3-hover-text-light-green">Play</li>
            <li id="menu_item_fullscreen" class="w3-btn w3-hover-text-light-green">Fullscreen</li>
            <li id="menu_item_controls" class="w3-btn w3-hover-text-light-green">Controls</li>
            <li id="menu_item_console" class="w3-btn w3-hover-text-light-green">Log</li>
            <li id="menu_item_about" class="w3-btn w3-hover-text-light-green">About</li>
        </ul>
    </div>
    <canvas id="display" class="w3-container" style="background-color:black;height:100%;margin:0;padding:0;z-index:0;">
    </canvas>
    <div id="controls_view" class="w3-container " style="position:absolute;top:70px;z-index:2;background:transparent;">
        <form id='persist'>
            <table>
                <col width="2*">
                <col width="5*">
                <col width="100px">
                <tr>
                    <td>
                        <label for=gi_tempo>Tempo (chords/minute)</label>
                    <td>
                        <input class=persistent-element type=range min=.05 max=144 value=4 id=gi_tempo step=.001>
                    <td>
                        <output for=gi_tempo id=gi_tempo_output>4</output>
                </tr>
                <tr style="height:1em;"></tr>
                <tr>
                    <td>
                        <label for=gi_3_modr_start>Starting modulator ratio</label>
                    <td>
                        <input class=persistent-element type=range min=.2 max=2 value=1 id=gi_3_modr_start step=.001>
                    <td>
                        <output for=gi_3_modr_start id=gi_3_modr_start_output>1</output>
                </tr>
                <tr style="height:1em;"></tr>
                <tr>
                    <td>
                        <label for=gi_3_modr_end>Ending modulator ratio</label>
                    <td>
                        <input class=persistent-element type=range min=.2 max=2 value=1 id=gi_3_modr_end step=.001>
                    <td>
                        <output for=gi_3_modr_end id=gi_3_modr_end_output>1</output>
                </tr>
                <tr style="height:1em;"></tr>
                <tr>
                    <td>
                        <label for=gk_ReverbSC_feedback>Reverb delay feedback</label>
                    <td>
                        <input class=persistent-element type=range min=0 max=1 value=.89 id=gk_ReverbSC_feedback
                            step=.001>
                    <td>
                        <output for=gk_ReverbSC_feedback id=gk_ReverbSC_feedback_output>.89</output>
                </tr>
                <tr>
                    <td>
                        <label for=gk_ReverbSC_frequency_cutoff>Reverb highpass cutoff (Hz)</label>
                    <td>
                        <input class=persistent-element type=range min=0 max=20000 value=12000
                            id=gk_ReverbSC_frequency_cutoff step=.001>
                    <td>
                        <output for=gk_ReverbSC_frequency_cutoff id=gk_ReverbSC_frequency_cutoff_output>12000</output>
                </tr>
                <tr>
                    <td>
                        <label for=gi_ReverbSC_delay_modulation>Reverb delay modulation</label>
                    <td>
                        <input class=persistent-element type=range min=0 max=2 value=.05 id=gi_ReverbSC_delay_modulation
                            step=.001>
                    <td>
                        <output for=gi_ReverbSC_delay_modulation id=gi_ReverbSC_delay_modulation_output>.05</output>
                </tr>
                <tr style="height:1em;"></tr>
                <tr>
                <tr>
                    <td>
                        <label for=gk_MasterOutput_level>Master output level (dB)</label>
                    <td>
                        <input class=persistent-element type=range min=-40 max=40 value=-30 id=gk_MasterOutput_level
                            step=.001>
                    <td>
                        <output for=gk_MasterOutput_level id=gk_MasterOutput_level_output>-6</output>
                </tr>
            </table>
            <p>
                <input type="button" id='save' value="Save" class="w3-btn w3-hover-text-light-green" />
                <input type="button" id='restore' value="Restore" class="w3-btn w3-hover-text-light-green" />
                <input type="button" id='copy' value="Copy" class="w3-btn w3-hover-text-light-green" />
                <input type="button" id='paste' value="Paste" class="w3-btn w3-hover-text-light-green" />
                <input type="button" id='default' value="Defaults" class="w3-btn w3-hover-text-light-green" />
        </form>
    </div>
    <div id='console_view' class="w3-text-sand"
        style="position:absolute;top:70px;z-index:4;width:100vw;height:90vh;background:transparent;color;margin-left:53px;">
    </div>
    <div id="about_view" class="w3-container "
        style="position:absolute;top:70px;z-index:5;background:transparent;color:rgb(255, 255, 200, 67%);max-height: calc(100vh - 70px);overflow-y:auto;">
        <h1>Cloud Music No. 2</h1>
        <h3>Michael Gogins<br>
            October 2022</h3>

        <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License"
                style="border-width:0;" src="https://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a>
        <p>This work is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons
                Attribution-NonCommercial-ShareAlike 3.0 Unported License.</a>

        <p>This is an online piece of electroacoustic music, rendered in your Web
            browser using high-resolution audio. It will play indefinitely, never ending,
            always changing.

        <p>This piece is generated as a sort of musical dynamical system operating in
            chord space. Generated notes are sent to Csound for rendering in real time.
            The synthesized audio is then sampled (using a WebAudio Analyzer) to change
            the brightness of the lines in the visual scene, as a form of music
            visualization.

        <p>The notes are played by a Csound orchestra that is embedded in this Web
            page using my <a href="https://github.com/gogins/csound-wasm">WebAssembly
                build of Csound</a>. This in turn includes my
            <a href="https://github.com/gogins/csound-ac">CsoundAC</a> library for
            algorithmic composition.

        <p>Feel free to use this piece as a template for creating new pieces of this
            type... as long as it doesn't sound too much like this one!

        <p>Please report any problems you have playing this piece, or any ideas for
            enhancements, at <a href="https://github.com/gogins/cloud-music/issues">
                cloud-music issues</a>.

        <ul>
            <li>To view the source code of this piece, use your browser menu to view the
                page source.
            <li>To inspect or debug the code of this piece as it runs, use your browser
                menu to open the developer tools.
        </ul>

        <h2>Credits</h2>

        <p>The StrangeAttractor class in CsoundAC, which computes the 4-dimensional
            orbit of a system of 4 coupled ordinary differential equations, uses code
            inspired by Julien C. Sprott's book <a
                href="https://sprott.physics.wisc.edu/fractals/booktext/SABOOK.PDF"><b><i>
                        Strange Attractors</i></b></a>. The state of the system is mapped to indices
            of set-type, inversion, pitch-class transposition, and octavewise revoicing.
            In short, the chaotic orbit of this system becomes an unceasing flow of chord
            progressions.

        <p>My code in CsoundAC for working with chords, scales, and voice-leading
            implements basic ideas from <a href="http://dmitri.tymoczko.com/">Dmitri
                Tymoczko's work in music theory</a>.

        <p>Code for compiling and controlling shaders is adapted from <a
                href="https://www.shadertoy.com">ShaderToy.com</a>.

        <p>The algorithm for downsampling the video canvas is from <a
                href="https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf">Sveinn
                Steinarsson's MS thesis</a> with code from <a href="https://github.com/pingec/downsample-lttb">
                https://github.com/pingec/downsample-lttb</a>.

        <p>Csound instruments are directly copied with minor alterations from <a
                href="https://github.com/csound/examples/blob/master/csd/xanadu-high-resolution.csd">
                Joseph T. Kung's Csound piece <i><b>Xanadu</b></i></a>.
        <p>

            <a href="http://michaelgogins.tumblr.com">
                <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
                <svg version="1.1" id="Calque_1" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="36" height="36"
                    viewBox="0 0 256 256" enable-background="new 0 0 256 256" xml:space="preserve">
                    <g>
                        <g>
                            <g>
                                <rect x="0.24" y="0.167" fill="#314358" width="255.52" height="256" />
                            </g>
                        </g>
                        <g>
                            <path fill="#FFFFFF"
                                d="M168.08,170.918c-2.969,1.416-8.647,2.648-12.881,2.754c-12.783,0.342-15.264-8.979-15.367-15.736v-49.705
            h32.065V84.055h-31.954V43.382c0,0-23.008,0-23.383,0c-0.385,0-1.057,0.337-1.152,1.192c-1.368,12.448-7.192,34.296-31.416,43.032
            v20.624h16.16v52.167c0,17.863,13.176,43.24,47.959,42.641c11.736-0.201,24.77-5.113,27.648-9.354L168.08,170.918" />
                        </g>
                    </g>
                </svg>
            </a>

            <a href="https://github.com/gogins">
                <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
                <svg version="1.1" id="Calque_1" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="36" height="36"
                    viewBox="0 0 256 256" enable-background="new 0 0 256 256" xml:space="preserve">
                    <g>
                        <path
                            d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z"
                            fill="#161614"></path>
                    </g>
                </svg>
            </a>

    </div>

    <textarea id="csd" cols=80 rows=24 style="display:none;">

<CsoundSynthesizer>
<CsOptions>
-+msg_color=0 -m34 -d --sample-accurate -odac 
</CsOptions>
<CsInstruments> 
; These must all match the host as printed when Csound starts.
sr          =           48000
ksmps       =           128
nchnls      =           2
nchnls_i    =           1
0dbfs       =           100000

ga_instruments_left_out init 0
ga_instruments_right_out init 0

;-----------------------------------------------------------
;Instrument 3 : New FM algorithm, modified to produce large timbre
;               shifts using modulation of I and r. Detuned chorusing employed.
;-----------------------------------------------------------
gi_3_modr_start chnexport "gi_3_modr_start", 3
gi_3_modr_start init 1
gi_3_modr_end chnexport "gi_3_modr_end", 3
gi_3_modr_end init 1

            instr Kung3
ishift      =           4/1200               ;shift it 8/1200.
ipch        =           cpspch(p5)           ;convert parameter 5 to cps.
; There seems to be something wrong here. Do it step by step.
ioct       =           octpch(p5)       ;convert parameter 5 to oct.
aadsr       linsegr     0, p3/3, 1.0, p3/3, 1.0, p3/3, 0 ;ADSR envelope
amodi       linseg      0, p3/3, 5, p3/3, 3, p3/3, 0 ;ADSR envelope for I
amodr       linseg      gi_3_modr_start, p3, gi_3_modr_end              ;r moves from p6->p7 in p3 sec.
a1          =           amodi*(amodr-1/amodr)/2
a1ndx       =           abs(a1*2/20)            ;a1*2 is normalized from 0-1.
a2          =           amodi*(amodr+1/amodr)/2
a3          tablei      a1ndx, 3, 1             ;lookup tbl in f3, normal index
ao1         poscil3     a1, ipch, 2             ;cosine
a4          =           exp(-0.5*a3+ao1)
ao2         poscil3     a2*ipch, ipch, 2        ;cosine
a_left      poscil3     1000*aadsr*a4, ao2+cpsoct(ioct+ishift), 1 ;fnl outleft
a_right     poscil3     1000*aadsr*a4, ao2+cpsoct(ioct-ishift), 1 ;fnl outright
            ga_instruments_left_out += a_left 
            ga_instruments_right_out += a_right
prints "%-24s i %9.4f t %9.4f d %9.4f o %9.4f p6 %9.4f p7 %9.4f #%3d\n", nstrstr(p1), p1, p2, p3, p5, gi_3_modr_start, gi_3_modr_end, active(p1)
            endin
            
;--------------------------------------------------------
;Instrument 1 : plucked strings chorused left/right and
;       pitch-shifted and delayed taps thru exponential
;       functions, and delayed.
;--------------------------------------------------------
            instr Kung1
ishift      =           4/1200                  ;shift it.
ipch        =           cpspch(p5)              ;convert parameter 5 to cps.
ioct        =           octpch(p5)              ;convert parameter 5 to oct.
kvib        poscil3     1/120, ipch/50, 1      ;vibrato
ag          pluck       2000, cpsoct(ioct+kvib),   1000, 1, 1
agleft      pluck       2000, cpsoct(ioct+ishift), 1000, 1, 1
agright     pluck       2000, cpsoct(ioct-ishift), 1000, 1, 1
adamping    linsegr     0.0, 0.006, 1.0, p3 - 0.066, 1.0, 0.06, 0.0
ag          =           adamping * ag
agleft      =           adamping * agleft
agright     =           adamping * agright
af1         expon       .1, p3, 1.0             ;exponential from 0.1 to 1.0
af2         expon       1.0, p3, .1             ;exponential from 1.0 to 0.1
adump       delayr      2.0                     ;set delay line of 2.0 sec
atap1       deltap3     af1                     ;tap delay line with kf1 func.
atap2       deltap3     af2                     ;tap delay line with kf2 func.
ad1         deltap3     2.0                     ;delay 2 sec.
ad2         deltap3     1.1                     ;delay 1.1 sec.
            delayw      ag                      ;put ag signal into delay line.
a_left      =           agleft+atap1+ad1
a_right     =           agright+atap2+ad2
            ga_instruments_left_out += a_left
            ga_instruments_right_out += a_right
prints "%-24s i %9.4f t %9.4f d %9.4f o %9.4f #%3d\n", nstrstr(p1), p1, p2, p3, p5, active(p1)
            endin
            
;-------------------------------------------------------------
;Instrument 2 : plucked strings chorused left/right and
;       pitch-shifted with fixed delayed taps.
;------------------------------------------------------------
            instr Kung2
ishift      =           4/1200                  ;shift it.
ipch        =           cpspch(p5)              ;convert parameter 5 to cps.
ioct        =           octpch(p5)              ;convert parameter 5 to oct.
kvib        poscil3     1/120, ipch/50, 1       ;vibrato
ag          pluck       1000, cpsoct(ioct+kvib),   1000, 1, 1
agleft      pluck       1000, cpsoct(ioct+ishift), 1000, 1, 1
agright     pluck       1000, cpsoct(ioct-ishift), 1000, 1, 1
adamping    linsegr     0.0, 0.006, 1.0, p3 - 0.066, 1.0, 0.06, 0.0
ag          =           adamping * ag
agleft      =           adamping * agleft
agright     =           adamping * agright
adump       delayr      0.3                     ;set delay line of 0.3 sec
ad1         deltap3     0.1                     ;delay 100 msec.
ad2         deltap3     0.2                     ;delay 200 msec.
            delayw      ag                      ;put ag sign into del line.
a_left      =           agleft+ad1
a_right     =           agright+ad2
            ga_instruments_left_out += a_left
            ga_instruments_right_out += a_right
prints "%-24s i %9.4f t %9.4f d %9.4f o %9.4f #%3d\n", nstrstr(p1), p1, p2, p3, p5, active(p1)
            endin
           
gk_Reverb_feedback init 0.8
gi_Reverb_delay_modulation init 0.015
gk_Reverb_frequency_cutoff init 12000
instr ReverbSC
aleftout init 0
arightout init 0
; aoutL, aoutR reverbsc ainL, ainR, kfblvl, kfco[, israte[, ipitchm[, iskip]]]
aleftout, arightout reverbsc ga_instruments_left_out, ga_instruments_right_out, gk_Reverb_feedback, gk_Reverb_frequency_cutoff, sr, gi_Reverb_delay_modulation
outs aleftout, arightout
ga_instruments_left_out = 0
ga_instruments_right_out = 0
prints "%-24s i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", nstrstr(p1), p1, p2, p3, p4, p5, p7, active(p1)
endin

alwayson "ReverbSC"

</CsInstruments>
<CsScore>
f 0 1000000000
;       Score for final project in Digital Audio Processing
;       ---------------------------------------------------

;           Piece entitled :  X A N A D U (short version)
;                           Joseph T. Kung, 12/12/88
;            Instruments modified for higher precision
;                         Michael Gogins, 07/22/2006

;           The first part of the score will specify all function
;       tables used in the piece. The second part specifies
;       the instruments and notes. The latter is divided into
;       7 sections, each playing a chord on a different
;                 instrument.
;       The chords are uncommon guitar chords that use the open
;       B and E strings often. These will be transposed by
;       octaves on some chords.

;       Each instrument will play a chord for 15 seconds. The
;                 timbre
;       of the instrument will change in that interval and join
;       with the next instrument/chord sequence. Instrument 3
;       uses a modified FM synthesis technique. This is joined
;       by an additional plucked-string instrument
;       (instruments 1 and 2).
t 0 10
;   The Function Tables
;   -------------------
;All functions are post-normalized (max value is 1) if p4 is
;POSITIVE.

f1 0 524288  10 1      ;sine wave
f2 0 524288  11 1      ;cosine wave
f3 0 524288 -12 20.0  ;unscaled ln(I(x)) from 0 to 20.0

</CsScore>
</CsoundSynthesizer>

    </textarea>

    <script id="draw-shader-fs" type="x-shader/x-fragment">#version 300 es
        #line 472
        precision highp float;
        /**
         * These are all of the standard ShaderToy inputs. If any of these are 
         * used in this shader, they must be created and initialized in the 
         * JavaScript code.
         */
        uniform vec3 iResolution;
        // viewport resolution (in pixels)
        uniform float iTime;
        // shader playback time (in seconds)
        uniform float iTimeDelta;
        // render time (in seconds)
        uniform int iFrame;
        // shader playback frame
        uniform float iChannelTime[4];
        // channel playback time (in seconds)
        uniform vec3 iChannelResolution[4];
        // channel resolution (in pixels)
        uniform vec4 iMouse;
        // mouse pixel coords. xy: current (if MLB down), zw: click
        uniform sampler2D iChannel0;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel1;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel2;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel3;
        // input channel. XX = 2D/Cube
        uniform vec4 iDate;
        // (year, month, day, time in seconds)
        uniform float iSampleRate;
        // sound sample rate (i.e., 44100)
        
        /**
         * Theoretically, any fragment shader copied from the ShaderToy 
         * editor can replace the body of the mainImage function below, 
         * if all inputs actually used in the shader are defined and bound.
         */

        void mainImage(out vec4 _ufragColor, in vec2 _ufragCoord);
        out vec4 _ushadertoy_out_color;
        void main(){
          (_ushadertoy_out_color = vec4(0.0, 0.0, 0.0, 0.0));
          (_ushadertoy_out_color = vec4(1.0, 1.0, 1.0, 1.0));
          vec4 _ucolor = vec4(0.0, 0.0, 0.0, 1.0);
          mainImage(_ucolor, gl_FragCoord.xy);
          if ((_ushadertoy_out_color.x < 0.0))
          {
            (_ucolor = vec4(1.0, 0.0, 0.0, 1.0));
          }
          if ((_ushadertoy_out_color.y < 0.0))
          {
            (_ucolor = vec4(0.0, 1.0, 0.0, 1.0));
          }
          if ((_ushadertoy_out_color.z < 0.0))
          {
            (_ucolor = vec4(0.0, 0.0, 1.0, 1.0));
          }
          if ((_ushadertoy_out_color.w < 0.0))
          {
            (_ucolor = vec4(1.0, 1.0, 0.0, 1.0));
          }
          (_ushadertoy_out_color = vec4(_ucolor.xyz, 1.0));
        }
        float hash(int x) { return fract(sin(float(x))*7.847); } 

        float dSegment(vec2 a, vec2 b, vec2 c)
        {
            vec2 ab = b-a;
            vec2 ac = c-a;
            float h = clamp(dot(ab, ac)/dot(ab, ab), 0., 1.);
            vec2 point = a+ab*h;
            return length(c-point);
        }

        void mainImage( out vec4 fragColor, in vec2 fragCoord )
        {
            vec2 uv = (fragCoord.xy*2.-iResolution.xy) / iResolution.yy;
            vec3 color = vec3(0.);
            color = mix(vec3(0.325, 0.431, 0.364), color, abs(uv.x)*0.25);
            for(int i=0; i < 190; ++i)
            {
                vec2 a = vec2(hash(i)*2.-1., hash(i+1)*2.-1.);
                vec2 b = vec2(hash(10*i+1)*2.-1., hash(11*i+2)*2.-1.);
                vec3 lineColor = vec3(hash(10+i), hash(18+i*3), hash(5+i*10));
                ///float speed = b.y*0.15;
                float speed = b.y*0.25;
                float size = (0.005 + 0.3*hash(5+i*i*2)) + (0.5+0.5*sin(a.y*5.+iTime*speed))*0.1;
                a += vec2(sin(a.x*20.+iTime*speed), sin(a.y*15.+iTime*0.4*speed)*0.5);
                b += vec2(b.x*5.+cos(iTime*speed), cos(b.y*10.+iTime*2.0*speed)*0.5);
                float dist = dSegment(a, b, uv);
                float soundWave = .3+.3*texture(iChannel0, vec2(0.10, 0.2)).x;
                color += mix(lineColor, vec3(0.), smoothstep(0., 1.0, pow(dist/size, soundWave*(0.5+0.5*sin(iTime*2.+size+lineColor.x*140.))*0.20) ));
            }
            fragColor = vec4(color,1.0);
        }        
    </script>

    <script id="draw-shader-vs" type="x-shader/x-vertex">#version 300 es
        in vec2 inPos;
        void main() {
            gl_Position = vec4(inPos.xy, 0.0, 1.0);
        }
    </script>

    <script>

        var shader_program = null;
        var analyser = null;
        // Set up for high-resolution displays.
        var devicePixelRatio_ = window.devicePixelRatio || 1
        var canvas = document.getElementById("display");
        canvas.width = canvas.clientWidth * devicePixelRatio_;
        canvas.height = canvas.clientHeight * devicePixelRatio_;
        console.log("canvas.height: " + canvas.height);
        console.log("canvas.width:  " + canvas.width);
        var gl = canvas.getContext("webgl2", { antialias: true });
        if (!gl) {
            alert("Could not create webgl2 context.");
        }
        let extensions = gl.getSupportedExtensions();
        console.log("Supported extensions:\n" + extensions);
        if ("gpu" in navigator) {
            var gpu_adapter = navigator.gpu.requestAdapter();
            console.log("WebGPU adapter: " + gpu_adapter);
        } else {
            console.warn("WebGPU is not available on this platform.");
        }
        var EXT_color_buffer_float = gl.getExtension("EXT_color_buffer_float");
        if (!EXT_color_buffer_float) {
            alert("EXT_color_buffer_float is not available on this platform.");
        }
        var WEBGL_debug_shaders = gl.getExtension("WEBGL_debug_shaders");
        const audio_texture_level = 0;
        const audio_texture_internalFormat = gl.R32F;
        const audio_texture_width = 512;
        const audio_texture_height = 2;
        const audio_texture_border = 0;
        const audio_texture_srcFormat = gl.RED;
        const audio_texture_srcType = gl.FLOAT;
        var frequency_domain_data = new Uint8Array(audio_texture_width * 2);
        var time_domain_data = new Uint8Array(audio_texture_width * 2);
        var audio_data = new Float32Array(audio_texture_width * 2);
        var image_sample_buffer = new Uint8ClampedArray();

        var channel0_texture_unit = 0;
        var channel0_texture = gl.createTexture();
        channel0_texture.name = "channel0_texture";
        var channel0_sampler = gl.createSampler();
        channel0_sampler.name - "channel0_sampler";

        var current_events = new Map();
        var prior_events = current_events;
        var rendering_frame = 0;
        let spectral_tilt = 0;
        let totalLoudness = 0;
        const midpoint = audio_texture_width / 2;
        function write_audio_texture(analyser, texture_unit, texture, sampler) {
            if (analyser != null) {
                analyser.getByteFrequencyData(frequency_domain_data);
                analyser.getByteTimeDomainData(time_domain_data);
                for (let i = 0; i < audio_texture_width; ++i) {
                    // Map frequency domain magnitudes to [0, 1].
                    let sample = frequency_domain_data[i];
                    sample = sample / 255.;
                    audio_data[i] = sample;
                    totalLoudness += sample;
                }
                let audio_data_width = audio_texture_width * 2;
                for (let j = 0; j < audio_texture_width; ++j) {
                    // Map time domain amplitudes to [-1, 1].
                    let sample = time_domain_data[j];
                    sample = sample / 255.;
                    audio_data[audio_texture_width + j] = sample;
                    if (j < midpoint) {
                        spectral_tilt -= Math.abs(sample);
                    } else {
                        spectral_tilt += Math.abs(sample);
                    }
                }
            }

            gl.activeTexture(gl.TEXTURE0 + texture_unit);
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.bindSampler(texture_unit, sampler);
            gl.texImage2D(gl.TEXTURE_2D, audio_texture_level, audio_texture_internalFormat, audio_texture_width, audio_texture_height, audio_texture_border, audio_texture_srcFormat, audio_texture_srcType, audio_data);
            gl.samplerParameteri(sampler, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.samplerParameteri(sampler, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
            gl.samplerParameteri(sampler, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.samplerParameteri(sampler, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.samplerParameteri(sampler, gl.TEXTURE_WRAP_R, gl.CLAMP_TO_EDGE);
            gl.samplerParameteri(sampler, gl.TEXTURE_COMPARE_MODE, gl.NONE);
            gl.samplerParameteri(sampler, gl.TEXTURE_COMPARE_FUNC, gl.LEQUAL);
            if (false && analyser) { // For debugging.
                let is_texture = gl.isTexture(texture);
                let uniform_count = gl.getProgramParameter(shader_program, gl.ACTIVE_UNIFORMS);
                let uniform_index;
                for (let uniform_index = 0; uniform_index < uniform_count; ++uniform_index) {
                    uniform_info = gl.getActiveUniform(shader_program, uniform_index);
                    console.log(uniform_info);
                    const location = gl.getUniformLocation(shader_program, uniform_info.name);
                    const value = gl.getUniform(shader_program, location);
                    console.log("Uniform location: " + location);
                    console.log("Uniform value: " + value);
                }
                const unit = gl.getUniform(shader_program, shader_program.iChannel0);
                console.log("Sampler texture unit: " + unit);
                console.log("Texture unit: " + texture_unit);
                gl.activeTexture(gl.TEXTURE0 + texture_unit);
                let texture2D = gl.getParameter(gl.TEXTURE_BINDING_2D);
                console.log("Texture binding 2D " + texture2D);
                var debug_framebuffer = gl.createFramebuffer();
                gl.bindFramebuffer(gl.FRAMEBUFFER, debug_framebuffer);
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture2D, 0);
                if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
                    console.log("These attachments don't work.");
                }
                // Read the contents of the debug_framebuffer (data stores the pixel data).
                var data = new Float32Array(1024);
                // What comes out, should be what went in.
                gl.readPixels(0, 0, 512, 2, gl.RED, gl.FLOAT, data);
                //console.log("\nfrequency domain: \n" + data.slice(0, 512));
                //console.log("time domain: \n" + data.slice(512));
                gl.deleteFramebuffer(debug_framebuffer);
            }
        }

        (function load_scene() {
            var webgl_viewport_size;
            var webgl_buffers = {};
            var mouse_position = [0, 0, 0, 0];
            function create_scene() {
                canvas.addEventListener('mousemove', (e) => {
                    mouse_position = [e.clientX, e.clientY];
                });
                shader_program = gl.createProgram();
                for (let i = 0; i < 2; ++i) {
                    let shader_code = document.getElementById(i == 0 ? "draw-shader-vs" : "draw-shader-fs").text;
                    let shader_object = gl.createShader(i == 0 ? gl.VERTEX_SHADER : gl.FRAGMENT_SHADER);
                    gl.shaderSource(shader_object, shader_code);
                    gl.compileShader(shader_object);
                    let status = gl.getShaderParameter(shader_object, gl.COMPILE_STATUS);
                    if (!status) {
                        console.warn(gl.getShaderInfoLog(shader_object));
                    }
                    gl.attachShader(shader_program, shader_object);
                    gl.linkProgram(shader_program);
                    console.log("shader:" + WEBGL_debug_shaders.getTranslatedShaderSource(shader_object));
                }
                status = gl.getProgramParameter(shader_program, gl.LINK_STATUS);
                if (!status) {
                    console.warn(gl.getProgramInfoLog(shader_program));
                }
                shader_program.inPos = gl.getAttribLocation(shader_program, "inPos");
                shader_program.iMouse = gl.getUniformLocation(shader_program, "iMouse");
                shader_program.iResolution = gl.getUniformLocation(shader_program, "iResolution");
                shader_program.iTime = gl.getUniformLocation(shader_program, "iTime");
                shader_program.iTimeDelta = gl.getUniformLocation(shader_program, "iTimeDelta");
                shader_program.iFrame = gl.getUniformLocation(shader_program, "iFrame");
                shader_program.iChannel0 = gl.getUniformLocation(shader_program, "iChannel0");
                shader_program.iChannel1 = gl.getUniformLocation(shader_program, "iChannel1");
                shader_program.iChannel2 = gl.getUniformLocation(shader_program, "iChannel2");
                shader_program.iChannel3 = gl.getUniformLocation(shader_program, "iChannel3");
                shader_program.iSampleRate = gl.getUniformLocation(shader_program, "iSampleRate");
                gl.useProgram(shader_program);

                gl.uniform1f(shader_program.iSampleRate, 48000.);
                var pos = [-1, -1,
                    1, -1,
                    1, 1,
                -1, 1];
                var inx = [0, 1, 2, 0, 2, 3];
                webgl_buffers.pos = gl.createBuffer();
                gl.bindBuffer(gl.ARRAY_BUFFER, webgl_buffers.pos);
                gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(pos), gl.STATIC_DRAW);
                webgl_buffers.inx = gl.createBuffer();
                webgl_buffers.inx.len = inx.length;
                gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, webgl_buffers.inx);
                gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(inx), gl.STATIC_DRAW);
                gl.enableVertexAttribArray(shader_program.inPos);
                gl.vertexAttribPointer(shader_program.inPos, 2, gl.FLOAT, false, 0, 0);
                gl.enable(gl.DEPTH_TEST);
                gl.clearColor(0.0, 0.0, 0.0, 1.0);
                write_audio_texture(analyser, channel0_texture_unit, channel0_texture, channel0_sampler);
                window.onresize = resize;
                resize();
                requestAnimationFrame(render_scene);
            }

            function resize() {
                webgl_viewport_size = [window.innerWidth, window.innerHeight];
                canvas.width = webgl_viewport_size[0] * window.devicePixelRatio;
                canvas.height = webgl_viewport_size[1] * window.devicePixelRatio;
                image_sample_buffer = new Uint8ClampedArray(canvas.width * 4);
                prior_image_sample_buffer = new Uint8ClampedArray(canvas.width * 4);
                console.info("resize: image_sample_buffer.length: " + image_sample_buffer.length);
            }

            function clientWaitAsync(sync, flags, interval_ms) {
                return new Promise((resolve, reject) => {
                    function test() {
                        const result = gl.clientWaitSync(sync, flags, 0);
                        if (result === gl.WAIT_FAILED) {
                            reject();
                            return;
                        }
                        // This is the workaround for platforms where maximum 
                        // timeout is always 0.
                        if (result === gl.TIMEOUT_EXPIRED) {
                            setTimeout(test, interval_ms);
                            return;
                        }
                        resolve();
                    }
                    test();
                });
            }

            async function getBufferSubDataAsync(target, buffer, srcByteOffset, dstBuffer,
                /* optional */ dstOffset, /* optional */ length) {
                const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
                gl.flush();
                await clientWaitAsync(sync, 0, 10);
                gl.deleteSync(sync);
                gl.bindBuffer(target, buffer);
                gl.getBufferSubData(target, srcByteOffset, dstBuffer, dstOffset, length);
                gl.bindBuffer(target, null);
            }

            /**
             * Converts an RGB color value to HSV. The formula is 
             * adapted from http://en.wikipedia.org/wiki/HSV_color_space.
             * Assumes r, g, and b are in [0, 255] and
             * returns h, s, and v are in [0, 1].
             */
            var rgb_to_hsv = function (rgb) {
                r = rgb[0] / 255;
                g = rgb[1] / 255;
                b = rgb[2] / 255;
                var max = Math.max(r, g, b);
                var min = Math.min(r, g, b);
                var h, s, v = max;
                var d = max - min;
                s = max === 0 ? 0 : d / max;
                if (max == min) {
                    h = 0;
                } else {
                    // More efficient than switch?
                    if (max == r) {
                        h = (g - b) / d + (g < b ? 6 : 0);
                    } else if (max == g) {
                        h = (b - r) / d + 2;
                    } else if (max == b) {
                        h = (r - g) / d + 4;
                    }
                    h /= 6;
                }
                return [h, s, v];
            }

            async function readPixelsAsync(x, y, w, h, format, type, sample) {
                const buffer = gl.createBuffer();
                gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buffer);
                gl.bufferData(gl.PIXEL_PACK_BUFFER, sample.byteLength, gl.STREAM_READ);
                gl.readPixels(x, y, w, h, format, type, 0);
                gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
                await getBufferSubDataAsync(gl.PIXEL_PACK_BUFFER, buffer, 0, sample);
                gl.deleteBuffer(buffer);
            }

            /**
             * Adapts https://github.com/pingec/downsample-lttb from time 
             * series data to vectors of float HSV pixels. Our data is not 
             * [[time, value], [time, value],...], but rather 
             * [[pixel index0, hsv0[2]], [pixel index1, hsv1[2]], ...].
             */
            function downsample_lttb(data, buckets) {
                if (buckets >= data.length || buckets === 0) {
                    return data; // Nothing to do
                }
                let sampled_data = [],
                    sampled_data_index = 0;
                // Bucket size. Leave room for start and end data points
                let bucket_size = (data.length - 2) / (buckets - 2);
                // Triangles are points {a, b, c}.
                let a = 0,  // Initially a is the first point in the triangle
                    max_area_point,
                    max_area,
                    area,
                    next_a;
                sampled_data[sampled_data_index++] = data[a]; // Always add the first point
                for (let i = 0; i < buckets - 2; i++) {
                    // Calculate point average for next bucket (containing c)
                    let avg_x = 0,
                        avg_y = 0,
                        avg_range_start = Math.floor((i + 1) * bucket_size) + 1,
                        avg_range_end = Math.floor((i + 2) * bucket_size) + 1;
                    avg_range_end = avg_range_end < data.length ? avg_range_end : data.length;
                    let avg_range_length = avg_range_end - avg_range_start;
                    for (; avg_range_start < avg_range_end; avg_range_start++) {
                        avg_x += data[avg_range_start][0] * 1; // * 1 enforces Number (value may be Date)
                        avg_y += data[avg_range_start][1] * 1;
                    }
                    avg_x /= avg_range_length;
                    avg_y /= avg_range_length;
                    // Get the range for this bucket
                    let range_offs = Math.floor((i + 0) * bucket_size) + 1,
                        range_to = Math.floor((i + 1) * bucket_size) + 1;
                    // Point a
                    let point_a_x = data[a][0] * 1, // enforce Number (value may be Date)
                        point_a_y = data[a][1] * 1;
                    max_area = area = -1;
                    for (; range_offs < range_to; range_offs++) {
                        // Calculate triangle area over three buckets
                        area = Math.abs((point_a_x - avg_x) * (data[range_offs][1] - point_a_y) -
                            (point_a_x - data[range_offs][0]) * (avg_y - point_a_y)
                        ) * 0.5;
                        if (area > max_area) {
                            max_area = area;
                            max_area_point = data[range_offs];
                            next_a = range_offs; // Next a is this b
                        }
                    }
                    sampled_data[sampled_data_index++] = max_area_point; // Pick this point from the bucket
                    a = next_a; // This a is the next a (chosen b)
                }
                sampled_data[sampled_data_index++] = data[data.length - 1]; // Always add last
                return sampled_data; ///sampled_data;
            }

            /**
             * Translates one row of RGBA pixels, the width of the WebGL 
             * canvas, to Csound events. 
             *
             * https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf
             */
            var instrument_count = 9;
            var sampled_events = new Array();
            var playlist = new Map();
            var rendering_frame_rate = 400;
            var frame_translation_count = 0;
            var midi_key_begin = 36;
            var midi_key_range = 60;
            var maximum_voices = 8;
            var event_velocity_threshold = 100;
            var midi_key_end = midi_key_begin + midi_key_range;
            var sample_count = 0;
            var root_progression = 0;
            var on_events = new Array();
            var off_events = new Array();
            var playing_events = new Map();
            var event_tag = 0;
            var root_progressions = [2, 3, -4, 5, -1, 3];

            async function translate_sample_to_csound_events(maximum_events, threshold, parent_rendering_frame) {
                if (csound == null) {
                    return;
                }
                if (!csound.is_playing) {
                    return;
                }
                let x = 0;
                // y is zero at the bottom of the canvas.
                let y = 0;
                let width = canvas.width;
                let height = 1;
                let format = gl.RGBA;
                let type = gl.UNSIGNED_BYTE;
                readPixelsAsync(x, y, width, height, format, type, image_sample_buffer);
                // Translate the sample format from byte RGBA to float HSV.
                let hsv_image_sample = [];
                for (let byte_i = 0; byte_i < image_sample_buffer.length; byte_i = byte_i + 4) {
                    let rgb = image_sample_buffer.slice(byte_i, byte_i + 3);
                    let hsv = rgb_to_hsv(rgb);
                    hsv_image_sample.push([hsv_image_sample.length + 1, hsv[2], hsv]);
                }
                // Downsample the HSV samples.
                let downsampled_pixels = downsample_lttb(hsv_image_sample, midi_key_range);
                sampled_events.length = 0;
                on_events.length = 0;
                off_events.length = 0;
                score.clear();
                // Translate the HSV samples to Csound event vectors.
                // 0 is p1 insno (hsv[0](, tagged by downsampled pixel, 
                //   positive for on or negative for off.
                // 1 is p2 time always 0.
                // 2 is p3 duration (either hsv[1] or -1, must be 0 for off
                //   events).
                // 3 is p4 MIDI key (downsampled pixel).
                // 4 is p5 MIDI velocity (hsv[2]).
                for (let downsampled_pixel_i = 0; downsampled_pixel_i < downsampled_pixels.length; downsampled_pixel_i++) {
                    let hsv = downsampled_pixels[downsampled_pixel_i][2];
                    let instrument_number = 1 + (hsv[0] * instrument_count);
                    // The instrument number must have a unique fractional tag.
                    let time = 0;
                    let duration = 2 + (hsv[1] * 20);
                    let midi_key = Math.floor(midi_key_begin + downsampled_pixel_i);
                    let insno = sprintf("%d.%d", Math.floor(instrument_number), midi_key);
                    //let insno = sprintf("%d.%d", Math.floor(1), midi_key);
                    instrument_number = parseFloat(insno);
                    let midi_velocity = hsv[2] * 128;
                    let event_for_pixel = [instrument_number, time, duration, midi_key, midi_velocity];
                    sampled_events.push(event_for_pixel);
                }
                // Events that are playing but not loud enough, are turned off.
                for (let sampled_event_i = 0; sampled_event_i < sampled_events.length; sampled_event_i++) {
                    let sampled_event = sampled_events[sampled_event_i];
                    let key = sampled_event[0];
                    if ((sampled_event[4] < event_velocity_threshold) && (playing_events.has(key) == true)) {
                        let off_event = playing_events.get(key);
                        let instrument_number = off_event[0];
                        csound.KillInstance(instrument_number, "", 4, true);
                        //console.info("Turned off instrument number: " + instrument_number + ".");
                        playing_events.delete(key);
                    }
                }
                // Events that are loud enough but not playing, are turned on.
                for (let sampled_event_i = 0; sampled_event_i < sampled_events.length; sampled_event_i++) {
                    let sampled_event = sampled_events[sampled_event_i];
                    let key = sampled_event[0];
                    if ((sampled_event[4] >= event_velocity_threshold) && (playing_events.has(key) == false)) {
                        playing_events.set(key, sampled_event);
                        on_events.push(sampled_event);
                    }
                }
                CsoundAC.setCorrectNegativeDurations(false);
                // Limit number of on events, play N loudest only. Could also pick at random.
                on_events.sort(function (a, b) {
                    if (a[5] < b[5]) {
                        return 1;
                    }
                    if (b[5] < a[5]) {
                        return -1;
                    }
                    return 0;
                });
                let voices = Math.min(on_events.length, maximum_voices);
                for (let i = 0; i < voices; i++) {
                    let on_event = on_events[i];
                    let time = 0;
                    let duration = on_event[2];
                    let status = 144;
                    let instrument_number = on_event[0];
                    let key = on_event[3];
                    let velocity = on_event[4];
                    let phase = 0;
                    let pan = .01 + Math.random() * .8;
                    let depth = 0;
                    let height = 0;
                    let pitches = 4095;
                    score.add(time, duration, status, instrument_number, key, velocity, phase, pan, depth, height, pitches);
                }
                if (score.size() > 0) {
                    if (sample_count % 4 == 0) {
                        if (sample_count % 24 == 0) {
                            let scales = scale.modulations(chord);
                            if (scales.size() > 1) {
                                scale = scales.get(Math.floor(Math.random() * scales.size()));
                                csound_message_callback(sprintf("\n%s\n\n", scale.name()));
                            }
                        }
                        let root_progression = root_progressions[Math.floor(Math.random() * root_progressions.length)];
                        csound_message_callback(sprintf("\n%s\n\n", chord.eOP().name()));
                        chord = scale.transpose_degrees(chord, root_progression, 3)
                    }
                    CsoundAC.apply(score, chord, 0, 1000000, true);
                    let score_text = score.getCsoundScore(12., true);
                    csound.ReadScore(score_text);
                    // console.info(score_text);
                }
                sample_count++;
            }

            function render_scene(milliseconds) {
                gl.viewport(0, 0, canvas.width, canvas.height);
                gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
                let tyme = milliseconds / 1000;
                gl.uniform1f(shader_program.iTime, tyme);
                gl.uniform3f(shader_program.iResolution, canvas.width, canvas.height, 0);
                gl.uniform4f(shader_program.iMouse, mouse_position[0], mouse_position[1], 0, 0);
                write_audio_texture(analyser, channel0_texture_unit, channel0_texture, channel0_sampler);
                gl.drawElements(gl.TRIANGLES, webgl_buffers.inx.len, gl.UNSIGNED_SHORT, 0);
                //console.info(sprintf("render_scene:                      time: %9.4f frame: %5d", tyme, rendering_frame));
                rendering_frame++;
                requestAnimationFrame(render_scene);
            }
            create_scene();
        })();

    </script>

    <script>
        var CsoundAC = null;
        var strange_attractor = null;
        var csound = null;
        var score = null;
        var scale = null;
        var chord = null;
        var cs_random = null;
        var message_callback_buffer = "";
        var gk_modr_start = 1;
        var gk_modr_end = 1;
        var console_editor = ace.edit("console_view");
        //console_editor.setTheme("ace/theme/gob");
        console_editor.setReadOnly(true);
        console_editor.setShowPrintMargin(false);
        console_editor.setDisplayIndentGuides(false);
        console_editor.renderer.setOption("showGutter", false);
        console_editor.renderer.setOption("showLineNumbers", true);
        var csound_message_callback = function (message) {
            // Split in case the newline is in the middle of the message but 
            // not at the end?
            message_callback_buffer = message_callback_buffer + message;
            if (message_callback_buffer.endsWith("\n")) {
                console.log(message_callback_buffer);
                let lines = console_editor.getSession().getLength();
                // Prevent the console editor from hogging memory.
                if (lines > 5000) {
                    console_editor.getSession().removeFullLines(0, 2500);
                    lines = console_editor.getSession().getLength();
                }
                console_editor.moveCursorTo(lines, 0);
                console_editor.scrollToLine(lines);
                console_editor.insert(message_callback_buffer);
                message_callback_buffer = "";
            }
        };

        /** 
          * At each beat, generate a new chord.
          * I.e. the score generator is a sort of dynamical system.
          */
        var strange_attractor_initialized = false;
        var pitv = null;
        var tempo = 10 * 1000;
        var interval_id = null;
        function generate_score_fragment() {
            let tempo = document.getElementById("gi_tempo").value;
            let interval = 60 / tempo;
            if (!csound) {
                return;
            }
            if (csound.is_playing == false) {
                return;
            }
            if (strange_attractor_initialized) {
                strange_attractor.iterate_without_rendering();
                let n = strange_attractor.getIteration();
                let x = strange_attractor.getX();
                let y = strange_attractor.getY();
                let z = strange_attractor.getZ();
                let w = strange_attractor.getW();
                let xn = strange_attractor.getNormalizedX();
                let yn = strange_attractor.getNormalizedY();
                let zn = strange_attractor.getNormalizedZ();
                let wn = strange_attractor.getNormalizedW();
                let diagnostic = sprintf("iteration: %9d x:  %16.9f y:  %16.9f z:  %16.9f w:  %16.9f", n, x, y, z, w);
                console.log(diagnostic);
                diagnostic = sprintf("                     xn: %16.9f yn: %16.9f zn: %16.9f wn: %16.9f", xn, yn, zn, wn);
                let p = Math.floor(xn * pitv.countP);
                let i = Math.floor(yn * pitv.countI);
                let t = Math.floor(zn * pitv.countT);
                let v = Math.floor(wn * pitv.countV);
                let chord = pitv.toChord(p, i, t, v, false).get(0);
                csound_message_callback(sprintf("New chord: %s  %s\n", chord.toString(), chord.eOP().name()));
                let notes = []
                for (let voice = 0; voice < chord.voices(); voice++) {
                    let instrument = (voice % 3) + 1;
                    let time = 0;
                    let duration = interval;
                    let key = 24 + chord.getPitch(voice);
                    let dummy = 0;
                    // MIDI key 60 is octave 8.0.
                    let octave = Math.floor(key / 12) + 5;
                    let pc = Math.floor(key % 12) / 100;
                    let octave_pc = octave + pc;
                    let velocity = 60;
                    let pan = Math.random();
                    // The Kung orchestra uses these pfields:
                    // p1_1 p2_time p3_duration p4_dummy p5_oct_pc 
                    // p1_2 p2_time p3_duration p4_dummy p5_oct_pc 
                    // Note: p6 and p7 can each range in [.2, 2]. But these are now global variables/channels.
                    // p1_3 p2_time p3_duration p4_dummy p5_oct_pc p6_modr_start p7_modr_end
                    let note = sprintf("i %9.4f %9.4f %9.4f %9.4f %9.4f 1 1", instrument, time, duration, dummy, octave_pc);
                    notes.push(note)
                }
                let score_fragment = notes.join("\n");
                console.log(score_fragment);
                csound.ReadScore(score_fragment);
            }
            let interval_milliseconds = interval * 1000;
            setTimeout(generate_score_fragment, interval_milliseconds);
        }

        (async function () {
            CsoundAC = await createCsoundAC();
            strange_attractor = new CsoundAC.StrangeAttractor();
            conversions = new CsoundAC.Conversions();
            score = new CsoundAC.Score();
            scale = new CsoundAC.Scale("F major");
            chord = scale.chord(1, 5, 3);
            cs_random = new CsoundAC.Random();
            //CsoundAC.CHORD_SPACE_DEBUGGING(false);
            var txt = "\n";
            txt += "Browser CodeName: " + navigator.appCodeName + "\n";
            txt += "Browser Name: " + navigator.appName + "\n";
            txt += "Browser Version: " + navigator.appVersion + "\n";
            txt += "Cookies Enabled: " + navigator.cookieEnabled + "\n";
            txt += "Browser Language: " + navigator.language + "\n";
            txt += "Browser Online: " + navigator.onLine + "\n";
            txt += "Platform: " + navigator.platform + "\n";
            txt += "User-agent header: " + navigator.userAgent + "\n";
            txt += "gl.VENDOR: " + gl.getParameter(gl.VENDOR) + "\n";
            txt += "gl.RENDERER: " + gl.getParameter(gl.RENDERER) + "\n";
            txt += "gl.VERSION: " + gl.getParameter(gl.VERSION) + "\n";
            txt += "gl.SHADING_LANGUAGE_VERSION: " + gl.getParameter(gl.SHADING_LANGUAGE_VERSION) + "\n";
            csound_message_callback(txt);
            csound_message_callback(CsoundAC.chord_space_version() + "\n");
            let CM = CsoundAC.chordForName("CM");
            CM = CM.T(-4.);
            csound_message_callback(CM.information());
            csound_message_callback(CM.information_debug(-1));
        }());

        window.onload = function () {
            $("#controls_view").css("display", "none");
            $("#about_view").css("display", "none");
            $("#console_view").css("display", "none");
            $("#menu_item_play").click(async function (event) {
                console.log("menu_item_play click...");
                if (csound == null) {
                    try {
                        csound_message_callback("Trying to load CsoundAudioNode...\n");
                        var AudioContext = window.AudioContext || window.webkitAudioContext;
                        var audioContext = new AudioContext();
                        await audioContext.audioWorklet.addModule('CsoundAudioProcessor.js').then(function () {
                            csound_message_callback("Creating CsoundAudioNode...\n");
                            csound = new CsoundAudioNode(audioContext, csound_message_callback);
                            csound_message_callback("CsoundAudioNode (AudioWorklet) is available in this JavaScript context.\n");
                            analyser = new AnalyserNode(audioContext);
                            analyser.fftSize = 2048;
                            console.log("Analyzer buffer size: " + analyser.frequencyBinCount);
                            csound.connect(analyser);
                            console.log("csound: " + csound);
                        }, function (error) {
                            csound_message_callback(error + '\n');
                        });
                        csound_image_player = new CsoundImagePlayer(csound, CsoundAC, canvas);
                    } catch (e) {
                        csound_message_callback(e + '\n');
                    }
                }
                if (csound.is_playing == false) {
                    let csd = await document.getElementById('csd').value;
                    console_editor.setValue("");
                    let result = await csound.CompileCsdText(csd);
                    csound_message_callback("CompileCsdText returned: " + result);
                    await csound.Start();
                    if (localStorage.length > 0) {
                        $('#restore').trigger('click');
                    } else {
                        // Tricky! Otherwise we get _patch_ defaults, probably 
                        // not correct; we need _html_ defaults.
                        $('#default').trigger('click');
                    }
                    await csound.Perform();
                    csound_message_callback("Csound is playing...\n");
                    scale = new CsoundAC.Scale("F major");
                    alert("Please wait, searching for strange attractor, this can take seconds to minutes...\n");
                    let tempo = document.getElementById("gi_tempo").value;
                    let interval = 1 / tempo;
                    let interval_milliseconds = interval * 1000;
                    if (strange_attractor_initialized == false) {
                        CsoundAC.Random.seed(30493);
                        strange_attractor.reset();
                        strange_attractor.setDimensionCount(4);
                        strange_attractor.setAttractorType(4);
                        cs_random.sample();
                        while (true) {
                            let not_found = strange_attractor.searchForAttractor();
                            console.log("code: " + strange_attractor.getCode());
                            if (not_found === false) {
                                break;
                            }
                        }
                        csound_message_callback(sprintf("Found strange attractor (code: %s)\n", strange_attractor.getCode()));
                        pitv = new CsoundAC.PITV();
                        pitv.initialize(4, 48, 1, true);
                        strange_attractor_initialized = true;
                    }
                    interval_id = setTimeout(generate_score_fragment, tempo);
                    $("#menu_item_play").html("Stop");
                } else {
                    await clearInterval(interval_id);
                    await csound.Stop();
                    await csound.Cleanup();
                    csound.Reset();
                    csound_message_callback("Csound is stopping...\n");
                    $("#menu_item_play").html("Play");
                }
            });
            $("#menu_item_fullscreen").click(function (event) {
                console.log("menu_item_fullscreen click...");
                const display = document.getElementById("display");
                if (display.requestFullscreen) {
                    display.requestFullscreen();
                } else if (display.webkitRequestFullscreen) {
                    display.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) {
                    display.msRequestFullscreen();
                }
            });
            $("#menu_item_controls").click(function (event) {
                console.log("menu_item_controls click...");
                $("#about_view").hide();
                $("#console_view").hide();
                if ($("#controls_view").is(":visible")) {
                    $("#controls_view").hide();
                } else {
                    $("#controls_view").show();
                }
            });
            $("#menu_item_console").click(function (event) {
                console.log("menu_item_console click...");
                $("#controls_view").hide();
                $("#about_view").hide();
                let v = document.getElementById("console_view");
                if ($("#console_view").is(":visible")) {
                    $("#console_view").hide();
                } else {
                    $("#console_view").show();
                    // Needed to make visible in place.
                    console_editor.resize(true);
                }
            });
            $("#menu_item_about").click(function (event) {
                console.log("menu_item_about click...");
                $("#controls_view").hide();
                $("#console_view").hide();
                if ($("#about_view").is(":visible")) {
                    $("#about_view").hide();
                } else {
                    $("#about_view").show();
                }
            });
            $(document).keydown(function (event) {
                console.log("document keydown...");
                if (event.keyCode === 'F11') {
                    $("#menu_item_fullscreen").trigger("click");
                }
            });
            $('input').on('input', async function (event) {
                var slider_value = parseFloat(event.target.value);
                if (csound) {
                    csound.SetControlChannel(event.target.id, slider_value);
                }
                var output_selector = '#' + event.target.id + '_output';
                $(output_selector).val(slider_value);
            });
            $('#save').on('click', function () {
                $('.persistent-element').each(function () {
                    localStorage.setItem(this.id, this.value);
                });
            });
            $('#restore').on('click', async function () {
                $('.persistent-element').each(function () {
                    this.value = localStorage.getItem(this.id);
                    if (csound) {
                        csound.SetControlChannel(this.id, parseFloat(this.value));
                    }
                    var output_selector = '#' + this.id + '_output';
                    $(output_selector).val(this.value);
                });
            });
            $('#copy').on('click', function () {
                let controls_json = JSON.stringify(localStorage);
                navigator.clipboard.writeText(controls_json);
                csound_message_callback("Copied controls state to system clipboard.\n");
            });
            $('#paste').on('click', async function () {
                navigator.clipboard.readText().then(function (controls_json) {
                    let controls_state = JSON.parse(controls_json);
                    for (let [key, value] of Object.entries(controls_state)) {
                        console.log(key, value);
                    }
                    $('.persistent-element').each(function () {
                        this.value = localStorage.getItem(this.id);
                        if (csound) {
                            csound.SetControlChannel(this.id, parseFloat(this.value));
                        }
                        var output_selector = '#' + this.id + '_output';
                        $(output_selector).val(this.value);
                    });
                    csound_message_callback("Pasted controls state from system clipboard.\n");
                });
            });
            $('#default').on('click', function () {
                $('.persistent-element').each(function () {
                    this.value = this.defaultValue;
                    if (csound) {
                        csound.SetControlChannel(this.id, parseFloat(this.value));
                    }
                    var output_selector = '#' + this.id + '_output';
                    $(output_selector).val(this.value);
                });
            });
            // Reset controls to defaults every time the window loads!
            $("#default")[0].click();

        };
    </script>

</html>